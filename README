photospline

A collection of tools for fitting large, multidimensional tables of
data (in particular, Photonics tables) to tensor-product B-spline surfaces.

Authors: Nathan Whitehorn, Jakob van Santen, Sven LaFebre

# Rationale

Muons and charged-particle showers in the IceCube detector volume emit
Cherenkov photons that, as they travel through the ice, are scattered and
absorbed to varying degrees. As a consequence, light arrives at the PMT spread
out in time. A correct description of these delays is critical both for
simulation and reconstruction.

A simple and accurate analytic parameterization of the delay is elusive, as
optical properties of the ice change with depth. The degree of scattering a
photon experiences and its chance of being absorbed depend on the path it
takes through the ice layers. The approach favored so far is to simulate the
propagation of light from a source with a particular emission pattern (such as
an electromagnetic shower) through the ice layers and to tabulate the
probability of it being detected by a photomultiplier at various points in the
ice. Events can be simulated based on numbers looked up from the tables and
reconstructed by finding the best fit between the measured delay times and the
amplitudes stored in the tables. The photon-propagation simulation package
(Photonics, originally written for the AMANDA detector) provides a library for
reading and linearly interpolating between the values stored in the tables.

The difficultly, as with any numerical simulation, is the tables can quickly
become too large to fit in the memory of currently-available computers, and
thus have to be binned rather coarsely. The binning and linear interpolation
can create sharp edges in the evaluated time-delay probability density
function; these are both unphysical (a problem for simulation) and difficult
for a numerical minimizer to deal with (a problem for reconstruction).

# Spline surfaces

A variant on this approach is to simulate photon propagation on a very fine
grid and fit this to a tensor-product B-spline surface, yielding a
semi-analytic parameterization whose coefficient table is much smaller than
the original table but still describes the data in the table.

## B-splines

B-splines are piecewise polynomials with local support. A set of B-splines is
fully defined by a set of knots, or points where the splines meet. An n-th
order spline spans n + 2 knots and has n - 1 nonzero derivatives. A spline
surface is defined by a set of knots and the coefficients of each spline in
the set. Since the supports of the splines overlap, the value of the spline
surface at a given point is a linear combination of the values of the locally
supported splines. Thus, the problem of determining the spline coefficients
that best approximate a given data set is linear, and can be solved by
well-established methods of linear algebra.

## Linear least squares

Given a set of knots k and data b(y), one can build up a matrix A that
describes the value of each spline function evaluated at each point y. The
spline surface evaluated at y is then A*x, where x is the set of spline
coefficients. The best set of coefficients is the one that minimizes the
squared differences between the spline surface and b, or

	min||Ax-b||.

Using the definition of the 2-norm, the location of the minimum is given by
the solution to

	At*A*x = At*b,

where At is the transpose of A. These are called the ``normal equations.'' As
long as A has full rank (that is, the columns are linearly independent), there
is a unique min||Ax-b|| and the normal equations have a solution. In this
case, AtA is symmetric and positive-definite, so the normal equations can be
solved by the relatively efficient Cholesky decomposition.

## Regularization; P-splines

Often it is desirable that the spline surface not just fit the data at the
grid points, but also be free of spikes and large swings between the points.
This can be encouraged by introducing a ``penalty matrix'' D_n that when
multiplied with the coefficient vector gives the differences between the n-th
order derivatives of neighboring splines. The problem is then finding a
solution to

	min||Ax-b + \lambda*Dx||,

where \lambda is a positive number that determines the strength of the
smoothing. For example, D_1 will encourage linearity by penalizing curvature,
and D_2 will smooth by encouraging constant curvature. This is a kind of
Tikhonov regularization, and leads to a set of modified normal equations:

	At*A*x + \lambda*DtD*x = At*b.

## Formulating the normal equations

It is important to note that the size of the normal equations depends only on
the number of spline coefficients, not on the number of data points. In
particular, since A has n_splines columns and n_data rows, At*A is vastly
smaller than A itself when the number of splines is smaller than the number of
data points. For example, when fitting 30 million data points with 100k
splines (a typical and perfectly reasonable scenario), A would take up 2.4 TB
of RAM if stored in dense form.

Luckily, there exist methods to formulate the normal equations without ever
explicitly calculating A in the case where the knots are also on a grid. This
is the core trick that makes this fitting method feasible.

## Enforcing monotonicity in one dimension

When fitting Photonics tables, we fit the photon arrival time CDF rather than
the PDF. This has advantages for computational efficiency in reconstruction
(one can choose an equal-entries binning scheme for the measured pulses
without sacrificing any computational time), but introduces an extra
complication to the fit. For the PDF to represent a genuine probability
density, the CDF must be strictly monotonic. There is a way to express this
constraint in a linear fashion by transforming the B-spline basis to a
so-called T-spline (``trapezoidal'') basis, where the first basis function is
the sum of B-splines 1--N, the second the sum of 2--N, etc. In this basis,
monotonicity in the T-splined dimension is equivalent to all the spline
coefficients being positive. This is a variant of vanilla linear least-squares
called non-negative least squares.

The non-negative least squares problem is usually solved as a sequence of
equality-constrained problems, where the coefficients that would otherwise go
negative are actively constrained to 0 and the remainder are solved for using
the standard unconstrained methods. As this is an iterative procedure, it is
slower than solving the unconstrained problem, but algorithms exist that are
provably finite to within numerical limits. We have implemented one of these
as part of this package.

# Dependencies, installation

The bits of photospline needed to read and evaluate spline tables depend only
on gsl and cfitsio from I3 ports. These will be built by Cmake.

The actual fitting code depends on:
- Python, Numpy, and PyFITS for input and output
- Photonics for reading tables
- SuiteSparse (http://www.cise.ufl.edu/research/sparse/SuiteSparse/) for sparse matrix operations and Cholesky decompositions
- Fast BLAS and LAPACK implementations (we recommend GotoBLAS http://www.tacc.utexas.edu/tacc-projects/gotoblas2/) for numerical operations inside of SuiteSparse's supernodal Cholesky factorization

The easiest way to build and install the fitting code is to use the included
setup.py script. The steps are as follows:

If you want to read Level 2 Photonics tables:

1. Check out Photonics from the SVN repository at SourceForge (http://photonics.svn.sourceforge.net/)
2. ./configure; make in the Photonics source directory
3. Rename setup.cfg.example to setup.cfg and adjust the path to the Photonics source directory.

If you're okay with only reading Level 0/1 tables, you can use photonics from I3_PORTS.
1.-3. Set your I3_PORTS environment variable.

After that, in photospline/private: 
4. python setup.py install

# What is this stuff, and how do I use it?

## private/photo2numpy

This is a Python extension that reads Photonics tables into Numpy arrays.

## private/fitter

This is the home of the fitting scripts.

### private/fitter/glam-photonics.py

This is a script for fitting a single (cylindrically binned) level-0 table to
a B-spline surface. The knot placement has been optimized for cascades, but
you can choose the number of knots to use in each dimension as well as the
value of the smoothing parameter \lambda.

The meat of the script is the call to spglam.fit(). Parts of the code are
explicitly threaded, and if you use GotoBLAS, dense matrix operations inside
of the Choleksy decomposition will be threaded as well. You should set the
environment variable GOTO_NUM_THREADS to the maximum number of threads you'd
like the fitter to use.

### private/fitter/glam-photonics-spherical.py

This is a script for fitting spherically binned level-0 tables, again
optimized for cascades.

### private/fitter/glam-photoverify.py

This is a script that compares 1- or 2-dimensional slices of a table to the
fit B-spline surface. It requires PyGnuplot.

### private/fitter/stack-photonics.py

This script takes a collection of fit tables (each for a certain depth and
source zenith angle), combines them, and futzes with the knots to create a
pseudo-interpolating spline in the stacked dimensions. 

## private/fitter/glam

This is a pure-python implementation of GLAM, the algorithm for formulating
the normal equations without using infinite amounts of memory. Read this if
you want to understand how it works, as the C implementation is rather more
convoluted.

## private/fitter/glam/pyphotonics

This is a thin wrapper around photo2numpy, and is useful for interacting with
Photonics tables.

## private/cfitter

A pure-C implementation of our spline-fitting method.

### private/cfitter/glam.c

This is a pure-C implementation of GLAM that uses sparse matrices to formulate
the normal equations.

### private/cfitter/pyglam.c

The is the user interface to the C implementation of GLAM, and defines a
Python extension module (spglam) that exposes the same interface as the
pure-Python implementation.

### private/cfitter/nnls.c

This file contains two variant implementations of a fast but occasionally
cyclic non-negative least squares solver (Portugal/Judice/Vincente block
pivoting) and one that is provably finite (Adlers BLOCK3).

## private/util

Command-line tools for examining a spline surface.

## private/lib

C libraries for reading, evaluating, and sampling from spline surfaces

### private/lib/bspline.c

Basic functions for evaluating B-splines and their derivatives.

### private/lib/fitstable.c

Functions to read coefficients, knot vectors, and spline orders from a FITS
file.

### private/lib/splinepdf.c

Functions to sample from a spline-fit time PDF using an independence chain
Metropolis-Hastings sampler with an overdispersed Pandel function as a
proposal distribution. This code is used by I3PhotoSplineTable to sample from
the cumulative timing distribution.
